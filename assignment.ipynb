{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Œ Assignment: Model Optimization and Performance Tuning\n",
    "\n",
    "# ğŸš€ Solve It Yourself!\n",
    "\n",
    "This assignment is your chance to think like a data scientist. Donâ€™t rely on AI to do the work for you â€” the real learning happens when you explore, experiment, and problem-solve.\n",
    "\n",
    "Mistakes are okay â€” theyâ€™re part of the journey. Trust your skills, stay curious, and give it your best shot.\n",
    "\n",
    "Youâ€™ve got this! ğŸ’ª\n",
    "\n",
    "## ğŸ¯ Objective:\n",
    "\n",
    "- Explore Logistic Regression, K-Nearest Neighbors (KNN), Decision Tree (with CCP Post-Pruning), and Random Forest.\n",
    "- Optimize and compare model performance.\n",
    "\n",
    "## ğŸ“Œ Hint:\n",
    "\n",
    "- Make a result dataframe to append to it model name and performance metrics for final comparison (use visualization as well).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 1: Data Preparation\n",
    "1. **Download a dataset from Kagglehub**.\n",
    "2. **Load the dataset** and inspect its structure (columns, types, missing values).\n",
    "3. **Preprocess the data:**\n",
    "   - Handle missing values\n",
    "   - Encode categorical variables\n",
    "   - Scale numeric features\n",
    "\n",
    "ğŸ‘‰ **Question:** What preprocessing steps did you apply, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"wenruliu/adult-income-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_name = os.listdir(path)[0]\n",
    "\n",
    "full_path = os.path.join(path,data_name)\n",
    "\n",
    "df = pd.read_csv(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Part 2: Model Building\n",
    "\n",
    "### ğŸ”¹ 2.1 Logistic Regression\n",
    "- Build a baseline Logistic Regression model.\n",
    "- **Experiment:** Tune the `C` parameter (regularization strength).\n",
    "\n",
    "ğŸ‘‰ **Question:** How does changing `C` affect the modelâ€™s performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 2.2 K-Nearest Neighbors (KNN)\n",
    "- Train a KNN model with a default `k=5`.\n",
    "- **Experiment:**\n",
    "   - Test different values of `k`.\n",
    "   - Compare performance using `euclidean` vs. `manhattan` distance.\n",
    "\n",
    "ğŸ‘‰ **Question:** What is the best `k` for your dataset? Why did it perform better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ³ Part 3: Decision Tree with Pre-pruning & CCP (Post Pruning)\n",
    "- Train a Decision Tree with default settings.\n",
    "- Try pre-pruning hyperparameters.\n",
    "- Check feature importance attribute.\n",
    "- Extract `ccp_alpha` values using `cost_complexity_pruning_path`.\n",
    "- Build pruned trees for different `ccp_alpha` values.\n",
    "\n",
    "ğŸ‘‰ **Question:** What pre-pruning hyperparameter did you tune? How did you change them to increase performance?\n",
    "\n",
    "ğŸ‘‰ **Question:** Which `ccp_alpha` value gave the best results, and why?\n",
    "\n",
    "ğŸ‘‰ **Question:** How did the tree size change after pruning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ² Part 4: Random Forest\n",
    "- Train a Random Forest model with 100 trees.\n",
    "- **Experiment:** Vary `n_estimators` and `max_depth` and other hyperparameters.\n",
    "\n",
    "ğŸ‘‰ **Question:** How did changing these hyperparameters affect performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 5: Model Comparison and Optimization\n",
    "- Compare all models using Accuracy, Precision, Recall, and F1-score.\n",
    "- **Reflect:**\n",
    "   - Which model performed best?\n",
    "   - How did tuning improve performance?\n",
    "   - What trade-offs (e.g., overfitting vs. underfitting) did you observe?\n",
    "\n",
    "ğŸ‘‰ **Question:** Summarize which model you would choose for this dataset and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â­ Stretch Goal (Optional):\n",
    "- Use **GridSearchCV** or **RandomizedSearchCV** to fully optimize one model and retrieve best parameters and best model for each.\n",
    "- Visualize **feature importance** (especially for Decision Tree/Random Forest).\n",
    "\n",
    "ğŸ‘‰ **Bonus Question:** Did advanced tuning or feature importance insights change your final model choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlep-w1-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
